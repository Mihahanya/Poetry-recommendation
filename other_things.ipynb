{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('poetry.csv')\n",
    "df = df.drop(columns=df.columns[[5, 6, 7, 8]], axis=1)\n",
    "\n",
    "df = df[:]\n",
    "\n",
    "def proc_row(row):\n",
    "\tname = row['name'] if not pd.isna(row['name']) else row['text'].split('\\n')[0]\n",
    "\tauthor = row['author'] if not pd.isna(row['author']) else 'неизвестен'\n",
    "\n",
    "\tdate_from, date_to = row['date_from'], row['date_to']\n",
    "\tif pd.isna(date_from) and not pd.isna(date_to): date_from = date_to\n",
    "\tif pd.isna(date_to) and not pd.isna(date_from): date_to = date_from\n",
    "\tif pd.isna(date_to) and pd.isna(date_from): date_to = date_from = -1\n",
    "\t\n",
    "\t#text = '\\n'.join(row['text'].split('\\n')[:4])\n",
    "\ttext = row['text']\n",
    "\n",
    "\treturn pd.Series({'author': author, 'name': name, 'text': text, 'date_from': date_from, 'date_to': date_to})\n",
    "\n",
    "df = df.apply(proc_row, axis=1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "classifier = pipeline(\"zero-shot-classification\",\n",
    "\t\t\t\t\t  #device=0,\n",
    "                      model=\"cointegrated/rubert-base-cased-nli-threeway\")\n",
    "\n",
    "candidate_labels = open('labels.txt', encoding='utf-8').read().split('\\n')\n",
    "print('labels are:', candidate_labels, len(candidate_labels), len(set(candidate_labels)))\n",
    "\n",
    "for label in tqdm(candidate_labels):\n",
    "\tdf[label] = [v['scores'][0] for v in classifier(list(df['text'].values), label, multi_label=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import torch\n",
    "#\n",
    "#print(\"Available GPUs:\", torch.cuda.device_count())\n",
    "#print(torch.cuda.is_available())\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"zero-shot-classification\",\n",
    "\t\t\t\t\t  #device=0,\n",
    "                      model=\"cointegrated/rubert-base-cased-nli-threeway\")\n",
    "\n",
    "sequence_to_classify = df[\"text\"].values[3]\n",
    "\n",
    "candidate_labels = open('labels.txt', encoding='utf-8').read().split('\\n')\n",
    "\n",
    "result = classifier(sequence_to_classify, candidate_labels, multi_label=True)\n",
    "\n",
    "a = zip(result['labels'], result['scores'])\n",
    "a = sorted(list(a), key=lambda a: a[1], reverse=True)\n",
    "\n",
    "print(result['sequence'])\n",
    "print(a)\n",
    "\n",
    "\n",
    "# from transformers import pipeline\n",
    "# classifier = pipeline(\"zero-shot-classification\",\n",
    "#                       model=\"joeddav/xlm-roberta-large-xnli\", \n",
    "# \t\t\t\t\t  token=\"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\")\n",
    "\n",
    "# sequence_to_classify = \"За кого вы голосуете в 2020 году?\"\n",
    "# # we can specify candidate labels in Russian or any other language above:\n",
    "# candidate_labels = [\"Europe\", \"public health\", \"politics\"]\n",
    "# classifier(sequence_to_classify, candidate_labels)\n",
    "\n",
    "# from transformers import DistilBertTokenizer, DistilBertModel\n",
    "# import torch\n",
    "# import pandas as pd\n",
    "\n",
    "# model_name = \"distilbert-base-uncased\"\n",
    "# tokenizer = DistilBertTokenizer.from_pretrained(model_name)\n",
    "# model = DistilBertModel.from_pretrained(model_name)\n",
    "\n",
    "# def get_embeddings(texts):\n",
    "#     tokens = tokenizer.batch_encode_plus(texts, truncation=True, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         output = model(**tokens)\n",
    "\n",
    "#     embeddings = output.last_hidden_state.mean(dim=1).numpy()\n",
    "\n",
    "#     return embeddings\n",
    "\n",
    "# all_embeddings = get_embeddings(df['text'].tolist())\n",
    "\n",
    "# df['embeddings'] = all_embeddings.tolist()\n",
    "\n",
    "\n",
    "\n",
    "# # a = []\n",
    "# # for l in tqdm(df['text']):\n",
    "# #     a.append(get_emb(l))\n",
    "\n",
    "# #df['embedding'] = a\n",
    "\n",
    "# #df['embedding'] = df['text'].apply(get_emb)\n",
    "# df['embedding'] = get_emb(df['text'].values)\n",
    "\n",
    "# df.head()\n",
    "\n",
    "# объем, эпоха, поэт, по схожести (автора, стиха), ключевые фразы, поэма\\стихотворение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "emb_model = SentenceTransformer('sentence-transformers/distiluse-base-multilingual-cased-v2')\n",
    "#emb_model = SentenceTransformer('intfloat/multilingual-e5-large')\n",
    "#emb_model = SentenceTransformer('intfloat/multilingual-e5-small')\n",
    "#emb_model.to(device)\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained('intfloat/multilingual-e5-base')\n",
    "# model = AutoModel.from_pretrained('intfloat/multilingual-e5-base')\n",
    "# tokens_input_size = 512\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/LaBSE')\n",
    "model = AutoModel.from_pretrained('sentence-transformers/LaBSE')\n",
    "tokens_input_size = 256\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/distiluse-base-multilingual-cased-v2')\n",
    "# model = AutoModel.from_pretrained('sentence-transformers/distiluse-base-multilingual-cased-v2')\n",
    "# tokens_input_size = 128\n",
    "\n",
    "def average_pool(last_hidden_states: Tensor, attention_mask: Tensor) -> Tensor:\n",
    "    last_hidden = last_hidden_states.masked_fill(~attention_mask[..., None].bool(), 0.0)\n",
    "    return last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]\n",
    "\n",
    "def get_embedding_by_tokens(batch_dict):\n",
    "    outputs = model(**batch_dict)\n",
    "    embeddings = average_pool(outputs.last_hidden_state, batch_dict['attention_mask'])\n",
    "    embeddings = F.normalize(embeddings, p=2, dim=1)\n",
    "    return embeddings\n",
    "\n",
    "def get_embs(input_text):\n",
    "    all_tokens = tokenizer(input_text, truncation=False, return_tensors='pt')\n",
    "\n",
    "    tokens = all_tokens['input_ids'][0]\n",
    "    masks = all_tokens['attention_mask'][0]\n",
    "\n",
    "    seq_len = tokens.shape[0]\n",
    "\n",
    "    tokens_batch = tokens.chunk(math.ceil(seq_len/512))\n",
    "    masks_batch = masks.chunk(math.ceil(seq_len/512))\n",
    "\n",
    "    embeddings = []\n",
    "    for i in range(len(tokens_batch)):\n",
    "        batch = {'input_ids': tokens_batch[i][None, :], 'attention_mask':masks_batch[i][None, :]}\n",
    "        embedding = get_embedding_by_tokens(batch)[0]\n",
    "        embeddings.append(embedding.detach().numpy())\n",
    "\n",
    "    #return np.mean(embeddings, axis=0)\n",
    "    return embeddings"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
