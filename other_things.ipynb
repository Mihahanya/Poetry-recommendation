{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('poetry.csv')\n",
    "df = df.drop(columns=df.columns[[5, 6, 7, 8]], axis=1)\n",
    "\n",
    "df = df[:]\n",
    "\n",
    "def proc_row(row):\n",
    "\tname = row['name'] if not pd.isna(row['name']) else row['text'].split('\\n')[0]\n",
    "\tauthor = row['author'] if not pd.isna(row['author']) else 'неизвестен'\n",
    "\n",
    "\tdate_from, date_to = row['date_from'], row['date_to']\n",
    "\tif pd.isna(date_from) and not pd.isna(date_to): date_from = date_to\n",
    "\tif pd.isna(date_to) and not pd.isna(date_from): date_to = date_from\n",
    "\tif pd.isna(date_to) and pd.isna(date_from): date_to = date_from = -1\n",
    "\t\n",
    "\t#text = '\\n'.join(row['text'].split('\\n')[:4])\n",
    "\ttext = row['text']\n",
    "\n",
    "\treturn pd.Series({'author': author, 'name': name, 'text': text, 'date_from': date_from, 'date_to': date_to})\n",
    "\n",
    "df = df.apply(proc_row, axis=1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "classifier = pipeline(\"zero-shot-classification\",\n",
    "\t\t\t\t\t  #device=0,\n",
    "                      model=\"cointegrated/rubert-base-cased-nli-threeway\")\n",
    "\n",
    "candidate_labels = open('labels.txt', encoding='utf-8').read().split('\\n')\n",
    "print('labels are:', candidate_labels, len(candidate_labels), len(set(candidate_labels)))\n",
    "\n",
    "for label in tqdm(candidate_labels):\n",
    "\tdf[label] = [v['scores'][0] for v in classifier(list(df['text'].values), label, multi_label=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import torch\n",
    "#\n",
    "#print(\"Available GPUs:\", torch.cuda.device_count())\n",
    "#print(torch.cuda.is_available())\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"zero-shot-classification\",\n",
    "\t\t\t\t\t  #device=0,\n",
    "                      model=\"cointegrated/rubert-base-cased-nli-threeway\")\n",
    "\n",
    "sequence_to_classify = df[\"text\"].values[3]\n",
    "\n",
    "candidate_labels = open('labels.txt', encoding='utf-8').read().split('\\n')\n",
    "\n",
    "result = classifier(sequence_to_classify, candidate_labels, multi_label=True)\n",
    "\n",
    "a = zip(result['labels'], result['scores'])\n",
    "a = sorted(list(a), key=lambda a: a[1], reverse=True)\n",
    "\n",
    "print(result['sequence'])\n",
    "print(a)\n",
    "\n",
    "\n",
    "# from transformers import pipeline\n",
    "# classifier = pipeline(\"zero-shot-classification\",\n",
    "#                       model=\"joeddav/xlm-roberta-large-xnli\", \n",
    "# \t\t\t\t\t  token=\"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\")\n",
    "\n",
    "# sequence_to_classify = \"За кого вы голосуете в 2020 году?\"\n",
    "# # we can specify candidate labels in Russian or any other language above:\n",
    "# candidate_labels = [\"Europe\", \"public health\", \"politics\"]\n",
    "# classifier(sequence_to_classify, candidate_labels)\n",
    "\n",
    "# from transformers import DistilBertTokenizer, DistilBertModel\n",
    "# import torch\n",
    "# import pandas as pd\n",
    "\n",
    "# model_name = \"distilbert-base-uncased\"\n",
    "# tokenizer = DistilBertTokenizer.from_pretrained(model_name)\n",
    "# model = DistilBertModel.from_pretrained(model_name)\n",
    "\n",
    "# def get_embeddings(texts):\n",
    "#     tokens = tokenizer.batch_encode_plus(texts, truncation=True, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         output = model(**tokens)\n",
    "\n",
    "#     embeddings = output.last_hidden_state.mean(dim=1).numpy()\n",
    "\n",
    "#     return embeddings\n",
    "\n",
    "# all_embeddings = get_embeddings(df['text'].tolist())\n",
    "\n",
    "# df['embeddings'] = all_embeddings.tolist()\n",
    "\n",
    "\n",
    "\n",
    "# # a = []\n",
    "# # for l in tqdm(df['text']):\n",
    "# #     a.append(get_emb(l))\n",
    "\n",
    "# #df['embedding'] = a\n",
    "\n",
    "# #df['embedding'] = df['text'].apply(get_emb)\n",
    "# df['embedding'] = get_emb(df['text'].values)\n",
    "\n",
    "# df.head()\n",
    "\n",
    "# объем, эпоха, поэт, по схожести (автора, стиха), ключевые фразы, поэма\\стихотворение"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
