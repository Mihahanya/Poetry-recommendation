{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('poetry.csv')\n",
    "df = df.drop(columns=df.columns[[5, 6, 7, 8]], axis=1)\n",
    "\n",
    "df = df[:]\n",
    "\n",
    "def proc_row(row):\n",
    "\tname = row['name'] if not pd.isna(row['name']) else row['text'].split('\\n')[0]\n",
    "\tauthor = row['author'] if not pd.isna(row['author']) else 'неизвестен'\n",
    "\n",
    "\tdate_from, date_to = row['date_from'], row['date_to']\n",
    "\tif pd.isna(date_from) and not pd.isna(date_to): date_from = date_to\n",
    "\tif pd.isna(date_to) and not pd.isna(date_from): date_to = date_from\n",
    "\tif pd.isna(date_to) and pd.isna(date_from): date_to = date_from = -1\n",
    "\t\n",
    "\t#text = '\\n'.join(row['text'].split('\\n')[:4])\n",
    "\ttext = row['text']\n",
    "\n",
    "\treturn pd.Series({'author': author, 'name': name, 'text': text, 'date_from': date_from, 'date_to': date_to})\n",
    "\n",
    "df = df.apply(proc_row, axis=1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "classifier = pipeline(\"zero-shot-classification\",\n",
    "\t\t\t\t\t  #device=0,\n",
    "                      model=\"cointegrated/rubert-base-cased-nli-threeway\")\n",
    "\n",
    "candidate_labels = open('labels.txt', encoding='utf-8').read().split('\\n')\n",
    "print('labels are:', candidate_labels, len(candidate_labels), len(set(candidate_labels)))\n",
    "\n",
    "for label in tqdm(candidate_labels):\n",
    "\tdf[label] = [v['scores'][0] for v in classifier(list(df['text'].values), label, multi_label=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import torch\n",
    "#\n",
    "#print(\"Available GPUs:\", torch.cuda.device_count())\n",
    "#print(torch.cuda.is_available())\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"zero-shot-classification\",\n",
    "\t\t\t\t\t  #device=0,\n",
    "                      model=\"cointegrated/rubert-base-cased-nli-threeway\")\n",
    "\n",
    "sequence_to_classify = df[\"text\"].values[3]\n",
    "\n",
    "candidate_labels = open('labels.txt', encoding='utf-8').read().split('\\n')\n",
    "\n",
    "result = classifier(sequence_to_classify, candidate_labels, multi_label=True)\n",
    "\n",
    "a = zip(result['labels'], result['scores'])\n",
    "a = sorted(list(a), key=lambda a: a[1], reverse=True)\n",
    "\n",
    "print(result['sequence'])\n",
    "print(a)\n",
    "\n",
    "\n",
    "# from transformers import pipeline\n",
    "# classifier = pipeline(\"zero-shot-classification\",\n",
    "#                       model=\"joeddav/xlm-roberta-large-xnli\", \n",
    "# \t\t\t\t\t  token=\"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\")\n",
    "\n",
    "# sequence_to_classify = \"За кого вы голосуете в 2020 году?\"\n",
    "# # we can specify candidate labels in Russian or any other language above:\n",
    "# candidate_labels = [\"Europe\", \"public health\", \"politics\"]\n",
    "# classifier(sequence_to_classify, candidate_labels)\n",
    "\n",
    "# from transformers import DistilBertTokenizer, DistilBertModel\n",
    "# import torch\n",
    "# import pandas as pd\n",
    "\n",
    "# model_name = \"distilbert-base-uncased\"\n",
    "# tokenizer = DistilBertTokenizer.from_pretrained(model_name)\n",
    "# model = DistilBertModel.from_pretrained(model_name)\n",
    "\n",
    "# def get_embeddings(texts):\n",
    "#     tokens = tokenizer.batch_encode_plus(texts, truncation=True, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         output = model(**tokens)\n",
    "\n",
    "#     embeddings = output.last_hidden_state.mean(dim=1).numpy()\n",
    "\n",
    "#     return embeddings\n",
    "\n",
    "# all_embeddings = get_embeddings(df['text'].tolist())\n",
    "\n",
    "# df['embeddings'] = all_embeddings.tolist()\n",
    "\n",
    "\n",
    "\n",
    "# # a = []\n",
    "# # for l in tqdm(df['text']):\n",
    "# #     a.append(get_emb(l))\n",
    "\n",
    "# #df['embedding'] = a\n",
    "\n",
    "# #df['embedding'] = df['text'].apply(get_emb)\n",
    "# df['embedding'] = get_emb(df['text'].values)\n",
    "\n",
    "# df.head()\n",
    "\n",
    "# объем, эпоха, поэт, по схожести (автора, стиха), ключевые фразы, поэма\\стихотворение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "emb_model = SentenceTransformer('sentence-transformers/distiluse-base-multilingual-cased-v2')\n",
    "#emb_model = SentenceTransformer('intfloat/multilingual-e5-large')\n",
    "#emb_model = SentenceTransformer('intfloat/multilingual-e5-small')\n",
    "#emb_model.to(device)\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained('intfloat/multilingual-e5-base')\n",
    "# model = AutoModel.from_pretrained('intfloat/multilingual-e5-base')\n",
    "# tokens_input_size = 512\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/LaBSE')\n",
    "model = AutoModel.from_pretrained('sentence-transformers/LaBSE')\n",
    "tokens_input_size = 256\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/distiluse-base-multilingual-cased-v2')\n",
    "# model = AutoModel.from_pretrained('sentence-transformers/distiluse-base-multilingual-cased-v2')\n",
    "# tokens_input_size = 128\n",
    "\n",
    "def average_pool(last_hidden_states: Tensor, attention_mask: Tensor) -> Tensor:\n",
    "    last_hidden = last_hidden_states.masked_fill(~attention_mask[..., None].bool(), 0.0)\n",
    "    return last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]\n",
    "\n",
    "def get_embedding_by_tokens(batch_dict):\n",
    "    outputs = model(**batch_dict)\n",
    "    embeddings = average_pool(outputs.last_hidden_state, batch_dict['attention_mask'])\n",
    "    embeddings = F.normalize(embeddings, p=2, dim=1)\n",
    "    return embeddings\n",
    "\n",
    "def get_embs(input_text):\n",
    "    all_tokens = tokenizer(input_text, truncation=False, return_tensors='pt')\n",
    "\n",
    "    tokens = all_tokens['input_ids'][0]\n",
    "    masks = all_tokens['attention_mask'][0]\n",
    "\n",
    "    seq_len = tokens.shape[0]\n",
    "\n",
    "    tokens_batch = tokens.chunk(math.ceil(seq_len/512))\n",
    "    masks_batch = masks.chunk(math.ceil(seq_len/512))\n",
    "\n",
    "    embeddings = []\n",
    "    for i in range(len(tokens_batch)):\n",
    "        batch = {'input_ids': tokens_batch[i][None, :], 'attention_mask':masks_batch[i][None, :]}\n",
    "        embedding = get_embedding_by_tokens(batch)[0]\n",
    "        embeddings.append(embedding.detach().numpy())\n",
    "\n",
    "    #return np.mean(embeddings, axis=0)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\PROGRAMS\\conda\\envs\\torch_lm\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "[{'score': 0.5849229097366333, 'text_sim': 0.5849229097366333, 'req_sim': -0.03011651709675789, 'author': 'Вячеслав Иванов', 'name': 'EXIT COR ARDENS[4]', 'text': 'Моя любовь — осенний небосвод\\nНад радостью отпразднованной пира.\\nГляди: в краях глубокого потира\\nЗакатных зорь смесился желтый мед\\nИ тусклый мак, что в пажитях эфира\\nРасцвел луной. И благость темных вод\\nТворит вино божественных свобод\\nПричастием на повечерьи мира...\\n. . . . . . . . . . . . . . . . . . .\\n. . . . . . . . . . . . . . . . . . .\\n. . . . . . . . . . . . . . . . . . .\\n. . . . . . . . . . . . . . . . . . .\\n. . . . . . . . . . . . . . . . . . .\\n. . . . . . . . . . . . . . . . . . .', 'date': 1907, 'century': 'XX (20)', 'epoch': 'серебряный век, авангард', 'line_count': 14, 'word_count': 154}, {'score': 0.5822066068649292, 'text_sim': 0.5822066068649292, 'req_sim': -0.037488583475351334, 'author': 'Евгений Баратынский', 'name': 'Есть милая страна, есть угол на земле...', 'text': 'Есть милая страна, есть угол на земле,\\nКуда, где б ни были: средь буйственного стана,\\nВ садах Армидиных, на быстром корабле,\\nБраздящем весело равнины океана,\\nВсегда уносимся мы думою своей,\\nГде, чужды низменных страстей,\\nЖитейским подвигам предел мы назначаем,\\nГде мир надеемся забыть когда-нибудь\\nИ вежды старые сомкнуть\\nПоследним, вечным сном желаем.\\n. . . . . . . . . . . . . . . . . . . .\\n. . . . . . . . . . . . . . . . . . . .\\n. . . . . . . . . . . . . . . . . . . .\\n. . . . . . . . . . . . . . . . . . . .\\n. . . . . . . . . . . . . . . . . . . .\\n. . . . . . . . . . . . . . . . . . . .\\n. . . . . . . . . . . . . . . . . . . .\\n. . . . . . . . . . . . . . . . . . . .\\nЯ помню ясный, чистый пруд;\\nПод сению берез ветвистых,\\nСредь мирных вод его три острова цветут;\\nСветлея нивами меж рощ своих волнистых;\\nЗа ним встает гора, пред ним в кустах шумит\\nИ брызжет мельница. Деревня, луг широкой,\\nА там счастливый дом... туда душа летит,\\nТам не хладел бы я и в старости глубокой!\\nТам сердце томное, больное обрело\\nОтвет на всё, что в нем горело,\\nИ снова для любви, для дружбы расцвело\\nИ счастье вновь уразумело.\\nЗачем же томный вздох и слезы на глазах?\\nОна, с болезненным румянцем на щеках,\\nОна, которой нет, мелькнула предо мною.\\nПочий, почий легко под дерном гробовым:\\nВоспоминанием живым\\nНе разлучимся мы с тобою!\\nМы плачем... но прости! Печаль любви сладка,\\nОтрадны слезы сожаленья!\\nНе то холодная, суровая тоска,\\nСухая скорбь разуверенья.', 'date': -1, 'century': '', 'epoch': '', 'line_count': 40, 'word_count': 339}, {'score': 0.5818490386009216, 'text_sim': 0.5818490386009216, 'req_sim': -0.04424750804901123, 'author': 'Аполлон Григорьев', 'name': 'Ночь', 'text': 'Немая ночь, сияют мириады\\nНебесных звезд — вся в блестках синева:\\nТо вечный храм зажег свои лампады\\nВо славу божества.\\nНемая ночь,— и в ней слышнее шепот\\nТаинственных природы вечной сил:\\nТо гимн любви, пока безумный ропот\\nЕго не заглушил.\\nНемая ночь; но тщетно песнь моленья\\nБольному сердцу в памяти искать...\\nЕму смешно излить благословенья\\nИ страшно проклинать.\\nПред хором звезд невозмутимо-стройным\\nОно судьбу на суд дерзнет ли звать,\\nИли своим вопросом беспокойным\\nСозданье возмущать?\\n. . . . . . . . . . . . . . . . . . . .\\n. . . . . . . . . . . . . . . . . . . .\\n. . . . . . . . . . . . . . . . . . . .\\n. . . . . . . . . . . . . . . . . . . .\\nО нет! о нет! когда благословенья\\nЗабыты им средь суетных тревог,\\nЕму на часть, в час общий примиренья,\\nПослал забвенье Бог.\\nЗабвение о том, что половиной,\\nЧто лучшей половиною оно\\nВ живую жертву мудрости единой\\nДавно обречено...', 'date': 1845, 'century': 'XIX (19)', 'epoch': 'золотой век', 'line_count': 28, 'word_count': 192}]\n"
     ]
    }
   ],
   "source": [
    "from serv.poem_search import search_poems\n",
    "\n",
    "print(search_poems('здраваствуй', 3, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:8080\n",
      " * Running on http://192.168.1.110:8080\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [06/Feb/2024 22:56:58] \"OPTIONS /poem_request HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Feb/2024 22:57:03] \"POST /poem_request HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Feb/2024 22:57:13] \"OPTIONS /poem_request HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Feb/2024 22:57:17] \"POST /poem_request HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Feb/2024 22:57:53] \"OPTIONS /poem_request HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Feb/2024 22:57:58] \"POST /poem_request HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Feb/2024 22:58:19] \"OPTIONS /poem_request HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Feb/2024 22:58:23] \"POST /poem_request HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Feb/2024 22:58:37] \"OPTIONS /poem_request HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Feb/2024 22:58:41] \"POST /poem_request HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Feb/2024 22:59:45] \"OPTIONS /poem_request HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Feb/2024 22:59:52] \"POST /poem_request HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Feb/2024 23:00:54] \"OPTIONS /poem_request HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Feb/2024 23:00:58] \"POST /poem_request HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "from flask_cors import CORS\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_pickle('D:/PROJECTS/Poetry-recommendation/poetry_data_prepared.pkl')\n",
    "\n",
    "#def search_poems():\n",
    "#    return df.loc[:10, ['name', 'text', 'author', 'date']].to_dict(orient='records')\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "#CORS(app, resources={r\"/process_data\": {\"origins\": \"*\"}})\n",
    "\n",
    "@app.route('/poem_request', methods=['POST'])\n",
    "def process_data():\n",
    "    request_data = request.json\n",
    "\n",
    "    result_data = search_poems(request_data['request_text'], request_data['top_n'], request_data['search_priority'])\n",
    "    \n",
    "    return jsonify(result_data)\n",
    "    \n",
    "\n",
    "@app.route(\"/\")\n",
    "def index():\n",
    "    return \"<h1>Hello!</h1>\"\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=8080)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
